
# ðŸ§  AI2 Internal Assistant

AI2 is a powerful internal business assistant that allows employees to query company knowledge securely and intelligently. It leverages:

- ðŸ” **Document search with vector embeddings** (Cohere)
- ðŸ’¬ **LLM responses with RAG** (Together.ai)
- ðŸŒ **User-friendly web interface** (FastAPI + HTML)
- ðŸ” Runs locally, keeps your data private

---

## ðŸ“ Project Structure

```
ai-business-suite/
â”œâ”€â”€ agents/                  # AI agent logic
â”œâ”€â”€ core/                    # LLM router, embeddings, vector store
â”œâ”€â”€ api/                     # FastAPI server
â”œâ”€â”€ templates/               # HTML frontend
â”œâ”€â”€ static/                  # CSS styles
â”œâ”€â”€ db/                      # ChromaDB persistence
â”œâ”€â”€ main.py                  # CLI interface (optional)
â”œâ”€â”€ .env                     # API keys here
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md                # You're here!
```

---

## ðŸš€ Quickstart

### 1. Clone the Repo

```bash
git clone https://github.com/your-username/ai2-assistant.git
cd ai2-assistant
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

> Make sure you're using **Python 3.10+**

---

### 3. Add API Keys

Create a `.env` file in the root:

```
COHERE_API_KEY=your-cohere-key
TOGETHER_API_KEY=your-together-key
```

Get keys:
- [Cohere](https://dashboard.cohere.com/)
- [Together](https://www.together.ai/)

---

### 4. Ingest Your First PDF

Place a document in the root directory and name it `sample.pdf`. The assistant will automatically ingest it when you launch it.

---

### 5. Run the Web Interface

```bash
uvicorn api.server:app --reload
```

Then open [http://localhost:8000](http://localhost:8000) in your browser.

---

## ðŸ–¥ Features

- ðŸ“„ PDF ingestion using PyMuPDF
- ðŸ§  Cohere embeddings + ChromaDB
- ðŸ’¬ Together.ai for answering questions using Mistral or LLaMA 3
- ðŸ–¼ FastAPI + Jinja2 HTML frontend
- ðŸ”„ Full RAG chain via LangChain

---

## ðŸ”§ Customization

### Change the Model

Edit `core/llm_router.py`:

```python
model_name="mistralai/Mistral-7B-Instruct-v0.1"
```

You can try:
- `meta-llama/Llama-3-8b-chat-hf`
- `openchat/openchat-3.5-1210`
- See full list: https://api.together.ai/models

---

### Add More Documents

You can modify `main.py` or create a drag-and-drop UI for batch ingestion.

---

## ðŸ§ª Test Locally

```bash
python main.py
```

Use the terminal to ask questions from your ingested data.

---

## âœ¨ Coming Soon Ideas

- Slack or MS Teams bot integration
- Upload-anywhere document support
- Admin dashboard for usage/stats
- Access control by department/user

---

## ðŸ™Œ Credits

Built using:
- [LangChain](https://www.langchain.com/)
- [Cohere](https://cohere.com/)
- [Together AI](https://www.together.ai/)
- [FastAPI](https://fastapi.tiangolo.com/)
